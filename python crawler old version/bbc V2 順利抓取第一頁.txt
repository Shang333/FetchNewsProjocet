from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import time
import pandas as pd

def fetch_news(search_query):
    # 設置Selenium Webdriver
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service)

    # BBC搜索頁面的URL
    url = f"https://www.bbc.com/search?q={search_query}&filter=news"
    driver.get(url)

    # 等待頁面加載
    time.sleep(5)  # 可能需要調整等待時間

    # 使用Selenium尋找元素
    articles = driver.find_elements(By.CSS_SELECTOR, "div[data-testid='liverpool-card']")
    news_list = []
    
    for article in articles:
        title = article.find_element(By.CSS_SELECTOR, 'h2').text if article.find_elements(By.CSS_SELECTOR, 'h2') else 'No title found'
        link = 'https://www.bbc.com' + article.find_element(By.CSS_SELECTOR, 'a').get_attribute('href') if article.find_elements(By.CSS_SELECTOR, 'a') else 'No link found'
        summary = article.find_element(By.CSS_SELECTOR, 'p').text if article.find_elements(By.CSS_SELECTOR, 'p') else 'No summary found'
        date = article.find_element(By.CSS_SELECTOR, "span[data-testid='card-metadata-lastupdated']").text if article.find_elements(By.CSS_SELECTOR, "span[data-testid='card-metadata-lastupdated']") else 'No date found'
        
        news_list.append({
            'date': date,
            'title': title,
            'summary': summary,
            'link': link
        })

    driver.quit()
    return news_list

def save_to_csv(news_data, filename='news.csv'):
    # 確保列的順序
    df = pd.DataFrame(news_data, columns=['date', 'title', 'summary', 'link'])
    df.to_csv(filename, index=False)
    print(f'Data saved to {filename}')

# 使用示例
news_data = fetch_news('Carbon credit')
save_to_csv(news_data)
